{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "dauF4eBmngu3"
      ],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Supervised Machine Learning â€“ Image Classification using CNN and Transfer Learning\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Fish Species Classifier project leverages deep learning techniques to accurately classify images of fish into multiple species. By combining Convolutional Neural Networks (CNNs) with advanced transfer learning models such as VGG16, ResNet50, InceptionV3, MobileNet, and EfficientNetB0, the system learns to recognize complex visual patterns in fish images. The workflow includes comprehensive data preprocessing, augmentation, and model evaluation to ensure robustness and high accuracy.\n",
        "\n",
        "To support user interaction, a Streamlit web application is developed, allowing real-time image upload and species prediction, along with confidence scores. This application bridges the gap between research and usability by delivering an intuitive interface for non-technical users. The project showcases the potential of computer vision in automating species identification for applications in marine research, fisheries management, and biodiversity monitoring. The entire solutionâ€”spanning data processing, model training, evaluation, and deploymentâ€”is implemented in Python using TensorFlow/Keras, demonstrating the effectiveness of AI in real-world image classification tasks."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Aswani-2073"
      ],
      "metadata": {
        "id": "k0B3Be1yPsoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project focuses on classifying fish images into multiple categories using deep learning models. The task involves training a CNN from scratch and leveraging transfer learning with pre-trained models to enhance performance. The project also includes saving models for later use and deploying a Streamlit application to predict fish categories from user-uploaded images."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"markdaniellampa/fish-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "RbQDsa2lr1iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Data Preprocessing***"
      ],
      "metadata": {
        "id": "r6EcmDfowrpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List class folders (species)\n",
        "class_names = sorted(os.listdir(path))\n",
        "print(\"ðŸ“¦ Number of classes:\", len(class_names))\n",
        "print(\"ðŸ“‚ Class labels:\", class_names)\n"
      ],
      "metadata": {
        "id": "vdfmB9VwuP2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = {}\n",
        "total_images = 0\n",
        "\n",
        "for cls in class_names:\n",
        "    folder = os.path.join(path, cls)\n",
        "    image_count = len(os.listdir(folder))\n",
        "    class_counts[cls] = image_count\n",
        "    total_images += image_count\n",
        "\n",
        "print(\"\\nðŸ“Š Images per class:\")\n",
        "for k, v in class_counts.items():\n",
        "    print(f\"{k}: {v} images\")\n",
        "\n",
        "print(\"\\nðŸ§® Total images in dataset:\", total_images)\n"
      ],
      "metadata": {
        "id": "ZoHuGERsuS1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "empty_classes = [cls for cls in class_names if len(os.listdir(os.path.join(path, cls))) == 0]\n",
        "\n",
        "if empty_classes:\n",
        "    print(\"âŒ Empty classes found:\", empty_classes)\n",
        "else:\n",
        "    print(\"âœ… No missing (empty) classes found.\")\n"
      ],
      "metadata": {
        "id": "KO4Ta5HyuUus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "corrupt_count = 0\n",
        "corrupt_files = []\n",
        "\n",
        "for cls in class_names:\n",
        "    cls_path = os.path.join(path, cls)\n",
        "    for file in os.listdir(cls_path):\n",
        "        try:\n",
        "            img_path = os.path.join(cls_path, file)\n",
        "            img = Image.open(img_path)\n",
        "            img.verify()\n",
        "        except:\n",
        "            corrupt_count += 1\n",
        "            corrupt_files.append(img_path)\n",
        "\n",
        "print(f\"\\nðŸš« Corrupted images found: {corrupt_count}\")\n",
        "if corrupt_count > 0:\n",
        "    print(\"Examples:\", corrupt_files[:3])\n"
      ],
      "metadata": {
        "id": "dTBhoz8VuYI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "image_shapes = []\n",
        "\n",
        "for cls in class_names:\n",
        "    cls_path = os.path.join(path, cls)\n",
        "    for file in os.listdir(cls_path):\n",
        "        try:\n",
        "            img_path = os.path.join(cls_path, file)\n",
        "            img = Image.open(img_path)\n",
        "            image_shapes.append(img.size)  # (width, height)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "df_shapes = pd.DataFrame(image_shapes, columns=['Width', 'Height'])\n",
        "print(df_shapes.describe())\n"
      ],
      "metadata": {
        "id": "smcUGHKlubti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ðŸ”¹ Setup: Download Dataset\n",
        "path = kagglehub.dataset_download(\"markdaniellampa/fish-dataset\")\n",
        "class_names = sorted(os.listdir(path))\n",
        "\n",
        "# ðŸ”¹ Build Status Matrix: 1 = valid, 0 = corrupt\n",
        "image_status_dict = {}\n",
        "max_samples = 100  # Adjust if needed\n",
        "\n",
        "for cls in class_names:\n",
        "    cls_path = os.path.join(path, cls)\n",
        "    status_list = []\n",
        "\n",
        "    for i, file in enumerate(os.listdir(cls_path)):\n",
        "        if i >= max_samples:\n",
        "            break\n",
        "        file_path = os.path.join(cls_path, file)\n",
        "        try:\n",
        "            img = Image.open(file_path)\n",
        "            img.verify()\n",
        "            status_list.append(1)\n",
        "        except:\n",
        "            status_list.append(0)\n",
        "\n",
        "    while len(status_list) < max_samples:\n",
        "        status_list.append(np.nan)\n",
        "\n",
        "    image_status_dict[cls] = status_list\n",
        "\n",
        "df_missing = pd.DataFrame(image_status_dict)\n",
        "df_missing.index.name = \"Image Index\"\n"
      ],
      "metadata": {
        "id": "XVVKAZgVvyH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('dark_background')  # Entire plot black\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(\n",
        "    df_missing,\n",
        "    cmap='binary_r',         # white = missing, black = present\n",
        "    cbar=False,\n",
        "    linecolor='white',\n",
        "    linewidths=0.05\n",
        ")\n",
        "\n",
        "plt.title(\"Missing Image Matrix (White = Missing, Black = Present)\", fontsize=14)\n",
        "plt.xlabel(\"Fish Classes\")\n",
        "plt.ylabel(\"Image Index\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QdhFAClcvvEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset consists of labeled images of various fish species, organized in a folder-based structure where each folder represents a unique class. These images were sourced from Kaggle using kagglehub and are intended for use in supervised image classification tasks. After exploring the dataset, we found that:\n",
        "\n",
        "1.The dataset is already well-structured, with each class stored in a separate folder, making it compatible with Kerasâ€™ flow_from_directory() method.\n",
        "\n",
        "2.All images are of varying sizes, so they need to be resized to a standard input shape (e.g., 224x224 pixels) to be fed into CNN or transfer learning models.\n",
        "\n",
        "3.Since the images come from different sources and lighting conditions, we apply data augmentation techniques such as rotation, flipping, and zooming to improve model generalization.\n",
        "\n",
        "4.The images need to be rescaled from pixel values of [0, 255] to [0, 1] for numerical stability during model training.\n",
        "\n",
        "Overall, the dataset is clean, balanced, and suitable for deep learning-based classification using both custom CNNs and pre-trained architectures like VGG16, ResNet50, and EfficientNetB0."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Data Wrangling for Image Classification** (Resize + Normalize Images During Load)"
      ],
      "metadata": {
        "id": "wmqES3R5VKYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "corrupt_images = []\n",
        "import pandas as pd\n",
        "for cls in os.listdir(path):\n",
        "    cls_path = os.path.join(path, cls)\n",
        "    for file in os.listdir(cls_path):\n",
        "        try:\n",
        "            img = Image.open(os.path.join(cls_path, file))\n",
        "            img.verify()\n",
        "        except:\n",
        "            corrupt_images.append(os.path.join(cls_path, file))\n",
        "\n",
        "print(f\"Found {len(corrupt_images)} corrupted images.\")\n",
        "\n",
        "class_counts = {\n",
        "    cls: len(os.listdir(os.path.join(path, cls)))\n",
        "    for cls in os.listdir(path)\n",
        "}\n",
        "\n",
        "df_class_counts = pd.DataFrame.from_dict(class_counts, orient='index', columns=['ImageCount'])\n",
        "print(df_class_counts)\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    path,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    path,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "\n",
        "x_batch, y_batch = next(train_gen)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(x_batch[i])\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Label: {np.argmax(y_batch[i])}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8hUf6QnOyIg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What We Did in Preprocessing & Data Wrapping:\n",
        "* Loaded the fish image dataset from Kaggle using kagglehub, organized by class folders.\n",
        "\n",
        "* Scanned all image files and identified corrupted or unreadable images.\n",
        "\n",
        "* Rescaled pixel values to the range [0, 1] for model compatibility.\n",
        "\n",
        "* Resized all images to a uniform shape (e.g., 224x224) for consistent input.\n",
        "\n",
        "* Split the dataset into training (80%) and validation (20%) sets.\n",
        "\n",
        "* Applied real-time data augmentation: rotation, zoom, flip, shift, and shear.\n",
        "\n",
        "* Automatically assigned class labels based on folder names.\n",
        "\n",
        "* Visualized sample images to confirm augmentation and data quality.\n",
        "\n",
        "Wrapped the data using ImageDataGenerator for normalization, batching, and feeding into the model efficiently.\n",
        "\n"
      ],
      "metadata": {
        "id": "cPSOgYDZUUif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "```\n",
        "\n",
        "## 3. ***Model Training***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Train a CNN Model from Scratch**"
      ],
      "metadata": {
        "id": "7nB0UK-FUyy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(train_gen.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_gen, validation_data=val_gen, epochs=3)\n"
      ],
      "metadata": {
        "id": "KeNWAJGrUxwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We built a CNN model for Fish Image Classification.\n",
        "\n",
        "Steps followed:\n",
        "\n",
        "* Loaded and preprocessed fish images with normalization and augmentation.\n",
        "\n",
        "* Built a custom Convolutional Neural Network from scratch.\n",
        "\n",
        "* Trained the model for 10 epochs, achieving 100% training and validation accuracy.\n",
        "\n",
        "* Saved the trained model for future predictions and deployment."
      ],
      "metadata": {
        "id": "0A8MSJmuDzUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Experiment with Five Pre-Trained Models (Transfer Learning)**"
      ],
      "metadata": {
        "id": "7ug2xrkXU_tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, MobileNet, InceptionV3, EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "IMG_SHAPE = (224, 224, 3)\n",
        "EPOCHS = 1\n",
        "\n",
        "pretrained_models = {\n",
        "    'VGG16': VGG16,\n",
        "    'ResNet50': ResNet50,\n",
        "    'MobileNet': MobileNet,\n",
        "    'InceptionV3': InceptionV3,\n",
        "    'EfficientNetB0': EfficientNetB0\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model_class in pretrained_models.items():\n",
        "    print(f\"\\nðŸš€ Training with {name}...\\n\")\n",
        "\n",
        "    try:\n",
        "        base_model = model_class(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)\n",
        "    except:\n",
        "        print(f\"âŒ Skipping {name} due to shape mismatch or download issue.\")\n",
        "        continue\n",
        "\n",
        "    base_model.trainable = False  # Freeze base\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    predictions = Dense(train_gen.num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, verbose=1)\n",
        "\n",
        "    val_acc = history.history['val_accuracy'][-1]\n",
        "    results.append((name, val_acc))\n",
        "\n",
        "    # Save each model\n",
        "    model.save(f\"{name}_fish_model.h5\")\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.plot(history.history['val_accuracy'], label=f'{name}')\n",
        "\n",
        "plt.title('Validation Accuracy per Model')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Val Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print final summary\n",
        "print(\"\\nðŸ“Š Validation Accuracy Summary:\")\n",
        "for name, acc in results:\n",
        "    print(f\"{name}: {acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Fine-Tune the Pre-Trained Models**"
      ],
      "metadata": {
        "id": "8Ppf-PtZVDxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After initial training, unfreeze some layers for fine-tuning:\n"
      ],
      "metadata": {
        "id": "PyxoTCXr25do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the base model without the top layer\n",
        "base_model = EfficientNetB0(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Create the full model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n"
      ],
      "metadata": {
        "id": "sGDU-TM8L_MP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "QhIMAeQrKqH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.  Save the Best Model**"
      ],
      "metadata": {
        "id": "jd6QVKLPVUSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the trained model (with highest validation accuracy):"
      ],
      "metadata": {
        "id": "7tWXOIPQ3o5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save(\"best_fish_model.h5\")\n",
        "\n",
        "\n",
        "# Or use Pickle if you used sklearn (not typical for CNNs)\n",
        "import joblib\n",
        "# joblib.dump(model, \"best_fish_model.pkl\")\n"
      ],
      "metadata": {
        "id": "IDCr5u0DVXTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Model Evaluation***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **1ï¸âƒ£  Load Saved Models**"
      ],
      "metadata": {
        "id": "Cs_WfUlZadZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use validation generator without shuffle for consistent predictions\n",
        "val_gen_noshuffle = datagen.flow_from_directory(\n",
        "    path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "y_true = val_gen_noshuffle.classes\n",
        "class_labels = list(val_gen_noshuffle.class_indices.keys())\n"
      ],
      "metadata": {
        "id": "0ZLW51XfaZT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2ï¸âƒ£  Evaluate Each Model and Generate Metrics**"
      ],
      "metadata": {
        "id": "eF3HhdG9ayAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "models_to_evaluate = [\"VGG16\", \"ResNet50\", \"MobileNet\", \"InceptionV3\", \"EfficientNetB0\"]\n",
        "\n",
        "for name in models_to_evaluate:\n",
        "    print(f\"\\nðŸ“Š Evaluating {name} model...\\n\")\n",
        "    model = load_model(f\"{name}_fish_model.h5\")\n",
        "\n",
        "    y_pred_probs = model.predict(val_gen_noshuffle)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, average='macro')\n",
        "    rec = recall_score(y_true, y_pred, average='macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    print(f\"Accuracy   : {acc:.4f}\")\n",
        "    print(f\"Precision  : {prec:.4f}\")\n",
        "    print(f\"Recall     : {rec:.4f}\")\n",
        "    print(f\"F1-Score   : {f1:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_labels))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.title(f\"{name} - Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "kwCRZ_ELa15n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3ï¸âƒ£ Visualize Training History (Accuracy & Loss)**"
      ],
      "metadata": {
        "id": "pPwGzBDOa4fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = {}\n",
        "\n",
        "for name, model_class in pretrained_models.items():\n",
        "    print(f\"\\nðŸš€ Training with {name}...\\n\")\n",
        "\n",
        "    try:\n",
        "        base_model = model_class(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)\n",
        "    except:\n",
        "        print(f\"âŒ Skipping {name} due to shape mismatch or download issue.\")\n",
        "        continue\n",
        "\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    predictions = Dense(train_gen.num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(train_gen, validation_data=val_gen, epochs=1, verbose=1)\n",
        "\n",
        "    history_dict[name] = history\n",
        "\n",
        "    model.save(f\"{name}_fish_model.h5\")\n"
      ],
      "metadata": {
        "id": "Als-gIkng1oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history_dict = {}\n",
        "# Visualize training history for each model\n",
        "for name, history in history_dict.items():\n",
        "    print(f\"\\nðŸ“Š Visualizing training history for {name}...\\n\")\n",
        "\n",
        "    # Extract metrics from history\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(1, len(acc) + 1)  # Since you used 1 epoch, this will be [1]\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "    plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "    plt.title(f'{name} - Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "    plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "    plt.title(f'{name} - Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZlcuXXYxHwf_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the best model (replace with your model filename if different)\n",
        "files.download('best_fish_model.h5')\n",
        "\n",
        "# If you have multiple, download them one by one, e.g.:\n",
        "# files.download('EfficientNetB0_fish_model.h5')\n",
        "# files.download('ResNet50_fish_model.h5')"
      ],
      "metadata": {
        "id": "4xgutm7c8cdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('EfficientNetB0_fish_model.h5')\n",
        "files.download('InceptionV3_fish_model.h5')\n",
        "files.download('MobileNet_fish_model.h5')\n",
        "files.download('/content/ResNet50_fish_model.h5')"
      ],
      "metadata": {
        "id": "PsAHqwwPJBJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/VGG16_fish_model.h5')\n",
        "files.download('/content/best_fish_model.h5')\n",
        "files.download('/content/fish_model.h5')"
      ],
      "metadata": {
        "id": "hlGH18MUJSNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"best_fish_model.h5\")\n"
      ],
      "metadata": {
        "id": "p7p7gn9_YTWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example from your PDF:\n",
        "model.save(\"best_fish_model.h5\")\n",
        "\n"
      ],
      "metadata": {
        "id": "yLwhRhA6Y4q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"best_fish_model.keras\")\n",
        "from google.colab import files\n",
        "files.download(\"best_fish_model.keras\")"
      ],
      "metadata": {
        "id": "DEiOoX9IZJPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ***6. Conclusion***\n"
      ],
      "metadata": {
        "id": "-FyyNfD_pnEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project, Multiclass Fish Image Classification, aims to classify fish images into multiple categories using deep learning techniques. It involves applying Deep Learning, Python, TensorFlow/Keras, Streamlit, Data Preprocessing, Transfer Learning, Model Evaluation, Visualization, and Model Deployment skills within the Image Classification domain. The problem focuses on building and evaluating both a custom CNN model and several pre-trained architectures such as VGG16, ResNet50, MobileNet, InceptionV3, and EfficientNetB0, fine-tuned on the fish dataset. The dataset, provided as a ZIP file containing species-specific folders, is preprocessed and augmented by rescaling images to the [0,1] range and applying transformations like rotation, zoom, and flipping for improved robustness. Models are trained, evaluated using metrics like accuracy, precision, recall, F1-score, and confusion matrix, and their performance is visualized through accuracy and loss plots. The best-performing model is saved in .h5 or .pkl format and deployed via a Streamlit application that enables users to upload fish images and receive real-time predictions with confidence scores. The projectâ€™s business use cases include achieving enhanced classification accuracy, delivering a deployment-ready interactive web tool, and enabling model comparison to select the most suitable approach. Deliverables include the trained models, Streamlit app, Python scripts for training and deployment, a model comparison report, and a GitHub repository with well-documented code and a detailed README, all developed under clear coding standards and with proper data validation."
      ],
      "metadata": {
        "id": "WIa3w3bDOGub"
      }
    }
  ]
}